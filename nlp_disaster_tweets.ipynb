{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9873f7",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Disaster Tweets\n",
    "\n",
    "GitHub Repository: https://github.com/niju789/NLP-Disaster-Tweets\n",
    "\n",
    "## 1 - Introduction\n",
    "\n",
    "### 1.1 - Problem\n",
    "\n",
    "This project aims to develop and train a recurrent neural network (RNN) to classify tweets based on whether the tweet is about real disasters.\n",
    "\n",
    "### 1.2 - Data\n",
    "\n",
    "The data provided includes two CSV files, one of which is the training set and the other is the testing set. The training set contains 7,613 rows and the testing set contains 3,263 rows. Both sets contain the columns \"id\", \"keyword\", \"location\", and \"text\". The training set contains the additional column \"target\" where the value for each row is 1 if the tweet is about a real disaster and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9813a6",
   "metadata": {},
   "source": [
    "## 2 - Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 2.1 - Data Inspection\n",
    "\n",
    "#### 2.1.1 - File/Table Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6def1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load training and testing sets\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a10cb77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text   \n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...  \\\n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 rows of training set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a8c2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 rows of testing set\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e9237e",
   "metadata": {},
   "source": [
    "#### 2.1.2 - Samples by Classification\n",
    "\n",
    "Sample tweets for class 0 (not a real disaster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcfe4afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's up man?\n",
      "===\n",
      "I love fruits\n",
      "===\n",
      "Summer is lovely\n",
      "===\n",
      "My car is so fast\n",
      "===\n",
      "What a goooooooaaaaaal!!!!!!\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "# Print the \"text\" value of the first 5 samples where \"target\" is 0\n",
    "for i in range(5):\n",
    "    print(train[train['target'] == 0]['text'].iloc[i])\n",
    "    print('===')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7a64d",
   "metadata": {},
   "source": [
    "Sample tweets for class 1 (real disaster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b80a58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "===\n",
      "Forest fire near La Ronge Sask. Canada\n",
      "===\n",
      "All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
      "===\n",
      "13,000 people receive #wildfires evacuation orders in California \n",
      "===\n",
      "Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n",
      "===\n"
     ]
    }
   ],
   "source": [
    "# Print the \"text\" value of the first 5 samples where \"target\" is 1\n",
    "for i in range(5):\n",
    "    print(train[train['target'] == 1]['text'].iloc[i])\n",
    "    print('===')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b6fb3e",
   "metadata": {},
   "source": [
    "### 2.2 - Data Cleaning\n",
    "\n",
    "#### 2.2.1 - Missing Values\n",
    "\n",
    "The \"keyword\" and \"location\" columns of both the training and testing sets are expected to have missing values. On the other hand, the \"id\", \"text\", and \"target\" columns should not have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77ba5b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show number of missing values for each column in training set\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15608407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       26\n",
       "location    1105\n",
       "text           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show number of missing values for each column in testing set\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ed94d",
   "metadata": {},
   "source": [
    "#### 2.2.2 - Valid Values\n",
    "\n",
    "The \"target\" column in the training set should only contain the values 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de1221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "# Print the unique values in the \"target\" column of the training set\n",
    "print(train['target'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f29e9a",
   "metadata": {},
   "source": [
    "#### 2.2.3 - Data Cleaning Summary\n",
    "\n",
    "The \"id\" and \"text\" columns in both sets and the \"target\" column in the training set do not contain any missing values. Additionally, the \"target\" column in the training set only contains the values 0 and 1 as expected. Therefore, the data is clean to use.\n",
    "\n",
    "### 2.3 - Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0da7a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the unique \"target\" values and their counts\n",
    "values, counts = np.unique(train['target'], return_counts=True)\n",
    "\n",
    "plt.bar(values.astype(str), counts)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da346e",
   "metadata": {},
   "source": [
    "The distribution of labels for tweets in the training set is slightly uneven. However, given that there are thousands of samples of each class, this should not be an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c619b",
   "metadata": {},
   "source": [
    "### 2.4 - Plan of Analysis\n",
    "\n",
    "Based on the EDA, there is no need to significantly alter the usual process for text classification. Of course, a word embedding method would need to be used to represent the words/characters in the tweet numerically for the purpose of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ccce40",
   "metadata": {},
   "source": [
    "## 3 - Model Architecture\n",
    "\n",
    "### 3.1 - Word Embedding\n",
    "\n",
    "The Term Frequency - Inverse Document Frequency (TF-IDF) method will be used to extract the text from the tweets into a feature matrix. TF-IDF caculates the importance of a word in a document based on the number of times the word appears in the document and the number of documents the word appears in from the collection of documents. The reasoning for choosing this extraction method is that it gives more weight to words that are rare across all documents but appear more frequently in one document and less weight to words that appear frequently in every document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69cdc9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 73894)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), stop_words='english')\n",
    "X = tfidf.fit_transform(train['text']).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c77e28",
   "metadata": {},
   "source": [
    "### 3.2 - Architectures Considered\n",
    "\n",
    "#### 3.2.1 - Base Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee31027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 32)                2365664   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                528       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,366,209\n",
      "Trainable params: 2,366,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "\n",
    "def create_base_model():\n",
    "    model = Sequential([\n",
    "        SimpleRNN(units=32, activation='relu', input_shape=(1, X.shape[1])),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "create_base_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817004e1",
   "metadata": {},
   "source": [
    "The model takes as input an array of size 1 x 73,894. The first \"layer\" is a simple RNN with 32 neurons. The ReLU activation function is used after this RNN layer to introduce non-linearity. This is followed by a fully connected layer of 16 neurons. The ReLU activation function is used again following this layer. A dropout layer is then used to help reduce any overfitting by dropping 20% of the neurons in the model so far. The output layer uses the Sigmoid activation function since this is a binary classification problem where the output should be between 0 and 1. \n",
    "\n",
    "#### 3.2.2 - Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d014df7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 32)                9462656   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,463,201\n",
      "Trainable params: 9,463,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "def create_lstm_model():\n",
    "    model = Sequential([\n",
    "        LSTM(units=32, activation='relu', input_shape=(1, X.shape[1])),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "create_lstm_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db1f33",
   "metadata": {},
   "source": [
    "This architecture is similar to the base architecture, but the only difference being that this architecture uses an RNN with LSTM instead of a simple RNN.\n",
    "\n",
    "#### 3.2.3 - Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa09c4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 32)                7097088   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,097,633\n",
      "Trainable params: 7,097,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "def create_gru_model():\n",
    "    model = Sequential([\n",
    "        GRU(units=32, activation='relu', input_shape=(1, X.shape[1])),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "create_gru_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f51976",
   "metadata": {},
   "source": [
    "This architecture is similar to the base architecture, but the only difference being that this architecture uses an RNN with GRUs instead of a simple RNN.\n",
    "\n",
    "### 3.3 - Hyperparameters\n",
    "\n",
    "Due to limited resources in terms of computing power and time, the hyperparameters that will be considered are those involved in training a neural network.\n",
    "\n",
    "The hyperparameters that will be tuned are:\n",
    "- Number of epochs\n",
    "- Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8351fede",
   "metadata": {},
   "source": [
    "## 4 - Results and Analysis\n",
    "\n",
    "### 4.1 - Hyperparameter Tuning\n",
    "\n",
    "The hyperparameter tuning procedure will consider 10 and 20 as values for the number of epochs and 64, 128, and 256 as values for the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81582b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, train['target'].values, test_size=0.2, random_state=123)\n",
    "\n",
    "# Reshape the input to match RNN input requirements\n",
    "X_train = np.expand_dims(X_train, axis=1)\n",
    "X_val = np.expand_dims(X_val, axis=1)\n",
    "\n",
    "# Hyperparameters and values considered\n",
    "num_epochs = [10, 20]\n",
    "batch_sizes = [64, 128, 256]\n",
    "\n",
    "# Returns best # of epochs, batch size, validation accuracy, and model\n",
    "def tune_hyperparameters(create_model):\n",
    "    val_accs = {}\n",
    "    best_val_acc = 0\n",
    "    best_h_params = { 'num_epochs': None, 'batch_size': None }\n",
    "    best_hp_model = None\n",
    "    \n",
    "    for epochs in num_epochs:\n",
    "        val_accs[epochs] = {}\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f'# of epochs: {epochs}, batch size: {batch_size}')\n",
    "            model = create_model()\n",
    "            early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                callbacks=[early_stopping],\n",
    "                verbose=0\n",
    "            )\n",
    "            val_acc = max(history.history['val_accuracy'])\n",
    "            print(f'Validation accuracy: {val_acc}')\n",
    "            val_accs[epochs][batch_size] = val_acc\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_h_params['num_epochs'] = epochs\n",
    "                best_h_params['batch_size'] = batch_size\n",
    "                best_hp_model = model\n",
    "                \n",
    "    return val_accs, best_val_acc, best_h_params, best_hp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "786709e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs: 10, batch size: 64\n",
      "Validation accuracy: 0.810899555683136\n",
      "# of epochs: 10, batch size: 128\n",
      "Validation accuracy: 0.8154957294464111\n",
      "# of epochs: 10, batch size: 256\n",
      "Validation accuracy: 0.7905449867248535\n",
      "# of epochs: 20, batch size: 64\n",
      "Validation accuracy: 0.7951411604881287\n",
      "# of epochs: 20, batch size: 128\n",
      "Validation accuracy: 0.8010505437850952\n",
      "# of epochs: 20, batch size: 256\n",
      "Validation accuracy: 0.8049901723861694\n"
     ]
    }
   ],
   "source": [
    "base_val_accs, base_best_val_acc, base_best_h_params, base_best_hp_model = tune_hyperparameters(create_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44611864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.8154957294464111\n",
      "Best number of epochs: 10\n",
      "Best batch size: 128\n"
     ]
    }
   ],
   "source": [
    "print(f'Best validation accuracy: {base_best_val_acc}')\n",
    "print(f'Best number of epochs: {base_best_h_params[\"num_epochs\"]}')\n",
    "print(f'Best batch size: {base_best_h_params[\"batch_size\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd470022",
   "metadata": {},
   "source": [
    "The base architecture model trained with a batch size of 128 over 10 epochs gave the best validation accuracy.\n",
    "\n",
    "### 4.2 - Techniques to Improve Training or Performance\n",
    "\n",
    "Using the architectures that use LSTM and GRU, it may be possible to train a model with better performance. Hyperparameter tuning will be performed similar to that of the base architecture with the same hyperparameters and values considered.\n",
    "\n",
    "#### 4.2.1 - LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b5a0579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs: 10, batch size: 64\n",
      "Validation accuracy: 0.8043335676193237\n",
      "# of epochs: 10, batch size: 128\n",
      "Validation accuracy: 0.8056467771530151\n",
      "# of epochs: 10, batch size: 256\n",
      "Validation accuracy: 0.7839789986610413\n",
      "# of epochs: 20, batch size: 64\n",
      "Validation accuracy: 0.7977675795555115\n",
      "# of epochs: 20, batch size: 128\n",
      "Validation accuracy: 0.8030203580856323\n",
      "# of epochs: 20, batch size: 256\n",
      "Validation accuracy: 0.780039370059967\n"
     ]
    }
   ],
   "source": [
    "lstm_val_accs, lstm_best_val_acc, lstm_best_h_params, lstm_best_hp_model = tune_hyperparameters(create_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b942659d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.8056467771530151\n",
      "Best number of epochs: 10\n",
      "Best batch size: 128\n"
     ]
    }
   ],
   "source": [
    "print(f'Best validation accuracy: {lstm_best_val_acc}')\n",
    "print(f'Best number of epochs: {lstm_best_h_params[\"num_epochs\"]}')\n",
    "print(f'Best batch size: {lstm_best_h_params[\"batch_size\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97255ca3",
   "metadata": {},
   "source": [
    "The LSTM architecture model trained with a batch size of 128 over 10 epochs gave the best validation accuracy.\n",
    "\n",
    "#### 4.2.2 - GRU Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49fc0822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs: 10, batch size: 64\n",
      "Validation accuracy: 0.8063033223152161\n",
      "# of epochs: 10, batch size: 128\n",
      "Validation accuracy: 0.803676962852478\n",
      "# of epochs: 10, batch size: 256\n",
      "Validation accuracy: 0.8023637533187866\n",
      "# of epochs: 20, batch size: 64\n",
      "Validation accuracy: 0.8063033223152161\n",
      "# of epochs: 20, batch size: 128\n",
      "Validation accuracy: 0.8030203580856323\n",
      "# of epochs: 20, batch size: 256\n",
      "Validation accuracy: 0.7938279509544373\n"
     ]
    }
   ],
   "source": [
    "gru_val_accs, gru_best_val_acc, gru_best_h_params, gru_best_hp_model = tune_hyperparameters(create_gru_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c77a8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.8063033223152161\n",
      "Best number of epochs: 10\n",
      "Best batch size: 64\n"
     ]
    }
   ],
   "source": [
    "print(f'Best validation accuracy: {gru_best_val_acc}')\n",
    "print(f'Best number of epochs: {gru_best_h_params[\"num_epochs\"]}')\n",
    "print(f'Best batch size: {gru_best_h_params[\"batch_size\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c30c3",
   "metadata": {},
   "source": [
    "The GRU architecture model trained with a batch size of 64 over 10 epochs gave the best validation accuracy.\n",
    "\n",
    "### 4.3 - Results\n",
    "\n",
    "#### 4.3.1 - Base Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ac1ce44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {64: 0.810899555683136, 128: 0.8154957294464111, 256: 0.7905449867248535},\n",
       " 20: {64: 0.7951411604881287,\n",
       "  128: 0.8010505437850952,\n",
       "  256: 0.8049901723861694}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61edb56d",
   "metadata": {},
   "source": [
    "Hyperparameter tuning results for number of epochs and batch size for base architecture:\n",
    "\n",
    "|| 64 Batch Size | 128 Batch Size | 256 Batch Size |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| **10 Epochs** | 0.811 | 0.815 | 0.791 |\n",
    "| **20 Epochs** | 0.795 | 0.801 | 0.805 |\n",
    "\n",
    "#### 4.3.2 - LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32b1d4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {64: 0.8043335676193237,\n",
       "  128: 0.8056467771530151,\n",
       "  256: 0.7839789986610413},\n",
       " 20: {64: 0.7977675795555115, 128: 0.8030203580856323, 256: 0.780039370059967}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd3bbb",
   "metadata": {},
   "source": [
    "Hyperparameter tuning results for number of epochs and batch size for LSTM architecture:\n",
    "\n",
    "|| 64 Batch Size | 128 Batch Size | 256 Batch Size |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| **10 Epochs** | 0.804 | 0.806 | 0.784 |\n",
    "| **20 Epochs** | 0.798 | 0.803 | 0.780 |\n",
    "\n",
    "#### 4.3.3 - GRU Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4267432c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {64: 0.8063033223152161, 128: 0.803676962852478, 256: 0.8023637533187866},\n",
       " 20: {64: 0.8063033223152161,\n",
       "  128: 0.8030203580856323,\n",
       "  256: 0.7938279509544373}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba208205",
   "metadata": {},
   "source": [
    "Hyperparameter tuning results for number of epochs and batch size for GRU architecture:\n",
    "\n",
    "|| 64 Batch Size | 128 Batch Size | 256 Batch Size |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| **10 Epochs** | 0.806 | 0.804 | 0.802 |\n",
    "| **20 Epochs** | 0.806 | 0.803 | 0.794 |\n",
    "\n",
    "#### 4.3.4 - Summary\n",
    "\n",
    "Best accuracies achieved across architectures:\n",
    "\n",
    "| Architecture | Best Validation Accuracy |\n",
    "| :-: | :-: |\n",
    "| Base | 0.815 |\n",
    "| LSTM | 0.806 |\n",
    "| GRU | 0.806 |\n",
    "\n",
    "### 4.4 - Analysis\n",
    "\n",
    "The best validation accuracy obtained through hyperparameter tuning for the base architecture was 0.815. The best validation accuracies obtained for both the LSTM and GRU architectures were lower than the one for the base architecture. Despite LSTM and GRU having advantages over the base model, the lower validation accuracies for these models could indicate overfitting.\n",
    "\n",
    "### 4.5 - Test Data Prediction\n",
    "\n",
    "Creating the submission file for the Natural Language Processing with Disaster Tweets competition using the best base model obtained after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7977f078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test = tfidf.transform(test['text']).toarray()\n",
    "X_test = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "predictions = base_best_hp_model.predict(X_test)\n",
    "pred_labels = (predictions > 0.5).astype(int).reshape(-1)\n",
    "\n",
    "output = pd.DataFrame({'id': test['id'], 'target': pred_labels})\n",
    "output.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca638f36",
   "metadata": {},
   "source": [
    "The F1 score on the testing set was 0.794.\n",
    "\n",
    "## 5 - Conclusion\n",
    "\n",
    "In this project, an RNN was developed and trained with the goal of being able to classify whether a tweet is about a real disaster or not. Three different architectures were considered and compared. Based on hyperparameter tuning results, the model with the base architecture had better performance and the best number of epochs was 10 and the best batch size was 128. This gave a validation accuracy of 0.815.\n",
    "\n",
    "Two techniques to help improve the performance of the model were considered: LSTM and GRU. Using the LSTM architecture did not help improve performance since the best validation accuracy obtained was 0.806. Similarly, using the GRU architecture did not help improve performance since the best validation accuracy obtained was also 0.806. Based on these results, it is possible that these two techniques did not help since the model is overfitting.\n",
    "\n",
    "Some possible improvements to try in the future include decreasing the model complexity and trying different techniques to help improve performance. The models may be overfitting, so experimenting with different techniques that help reduce overfitting may be useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
